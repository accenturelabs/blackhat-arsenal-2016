{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIEM Data Exploration with Spark\n",
    "\n",
    "## Data Formatting\n",
    "<hr>\n",
    "\n",
    "### Data Source\n",
    "Data used in this example is from a market leading SIEM\n",
    "\n",
    "### File Names\n",
    "Individual CSV files are converted from CSV to Parquet files (see `architecture.pdf` for more info) then saved by hour with the name format `YYYY-MM-DD-HH`\n",
    "\n",
    "### Field Names\n",
    "Field names match from the header information from the original CSV\n",
    "\n",
    "## Config Parameters\n",
    "<hr>\n",
    "Set these variables to connect to your HDFS cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HDFS config parameters\n",
    "hdfsNameNode = \"10.0.0.1\"\n",
    "hdfsPort = \"8020\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Spark Libraries\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries for PySpark/SparkSQL\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql.functions import *\n",
    "# Create a SQLContext to use for SQL queries\n",
    "sq = SQLContext(sc)ÃŸ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "<hr>\n",
    "\n",
    "### Network communication lookup, from source subnet to multiple destinations\n",
    "\n",
    "#### SQL Example: \n",
    "```WHERE sourceAddress CONTAINS \"55.54.53.\" AND  ( ( destinationAddress = \"10.0.0.50\" )  OR  ( destinationAddress = \"10.0.0.51\" )  OR  ( destinationAddress = \"10.0.0.52\" ) )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Day\n",
    "data1 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-01*\")\n",
    "pdf1 = data1.filter(data1.sourceAddress.startswith(\"55.54.53.\")) \\\n",
    "    .filter(\"destinationAddress = '10.0.0.50' OR destinationAddress = '10.0.0.51' OR destinationAddress = '10.0.0.52'\") \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Week\n",
    "data2 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-0[1-7]*\")\n",
    "pdf2 = data2.filter(data2.sourceAddress.startswith(\"55.54.53.\")) \\\n",
    "    .filter(\"destinationAddress = '10.0.0.50' OR destinationAddress = '10.0.0.51' OR destinationAddress = '10.0.0.52'\") \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "<hr>\n",
    "\n",
    "### Account failed logon attempts lookup, using startswith keyword\n",
    "\n",
    "#### SQL Example:\n",
    "```WHERE destinationUserName startswith \"ads.\" AND categoryOutcome = \"/Failure\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Day\n",
    "data5 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-01*\")\n",
    "pdf5 = data5.filter(data5.destinationUserName.startswith(\"ads.\")) \\\n",
    "    .filter(data5.categoryOutcome == \"/Failure\") \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf5.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Week\n",
    "data6 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-0[1-7]*\")\n",
    "pdf6 = data6.filter(data6.destinationUserName.startswith(\"ads.\")) \\\n",
    "    .filter(data6.categoryOutcome == \"/Failure\") \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf6.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "<hr>\n",
    "\n",
    "### Malware infection lookup, particular keyword in message field\n",
    "\n",
    "#### SQL Example:\n",
    "```WHERE deviceVendor=\"Symantec\" AND message contains \"exe\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Day\n",
    "data3 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-01*\")\n",
    "pdf3 = data3.filter(data3.deviceVendor == \"Symantec\") \\\n",
    "    .filter(data3.message.like(\"%exe%\")) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "### One Week\n",
    "data4 = sq.read.parquet(\"hdfs://\"+hdfsNameNode+\":\"+hdfsPort+\"/data/2016-06-0[1-7]*\")\n",
    "pdf4 = data4.filter(data4.deviceVendor == \"Symantec\") \\\n",
    "    .filter(data4.message.like(\"%exe%\")) \\\n",
    "    .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Number of results\n",
    "len(pdf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Display the first 10 results\n",
    "pdf4.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LATEST-pySpark-1.6",
   "language": "python",
   "name": "pyspark16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
